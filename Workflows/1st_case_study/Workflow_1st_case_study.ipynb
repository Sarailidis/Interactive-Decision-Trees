{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"logo.png\" alt=\"logo\"; style=\"width:200px; height:200px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"color:rgb(49,112,223);\"> Interactive Decision Trees</h1><\\center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Interactive Decision Trees to increase interpretability by colour-coding groups of variables and constructing new composite variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we apply two functionalities of the iDTs toolbox:\n",
    "\n",
    " + Group the variables of the dataset based on their physical meaning and colour code the groups\n",
    " + Create new composite variables\n",
    " \n",
    "and we show how experts can increase the visual interpretability of the DT and reduce its complexity. We will use the Graphical User Interface we developed to show the above functionalities of the iDTs.\n",
    "\n",
    "The methodology described in this notebook was followed to produce the results of the 1st case study of the paper *Integrating Scientific Knowledge into Machine Learning using Interactive Decision Trees (Sarailidis et al. 2021, EMS)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Contents:\n",
    "\n",
    "1. Introduction\n",
    "    - 1.1 Description of the initial dataset\n",
    "2. Load the Dataset\n",
    "3. Derive the Statistically Optimal Tree (SOT)\n",
    "    - 3.1 Estimate the optimal values of certain parameters\n",
    "    - 3.2 Measure its classification accuracy\n",
    "4. Derive the interactive DT\n",
    "    - 4.1 Pre-group variables based on physical meaning and colour code the groups\n",
    "    - 4.2 Create new Composite variables\n",
    "    - 4.3 Evaluate its classification perfomance\n",
    "    \n",
    "5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction:\n",
    "\n",
    "## 1.1 Description of the dataset:\n",
    "\n",
    "We used the dataset from Almeida et al. (2017): \n",
    "\n",
    "- It consists of 10,000 combinations (data points) of 28 input variables of a slope stability model. The variables are model parameters characterising the slope geometry, soil and design storm properties and initial hydrological conditions.\n",
    "- The model output is the slope factor of safety (FoS) and according to its value we can distinguish two classes in the dataset: Stable (FoS>1) and Failure (otherwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load the dataset:\n",
    "\n",
    "We first need to load necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modules necessary for widgets\n",
    "import ipywidgets as widgets\n",
    "#Import the module for interactive construction and analysis of decision trees\n",
    "import InteractiveDT\n",
    "from InteractiveDT import iDT\n",
    "from InteractiveDT import iDTGUIfun\n",
    "#Suppress useless warnings\n",
    "import warnings\n",
    "#ignore by message\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we initialize the GUI we developed to import csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next three empty dictionaries we create are required as inputs for the initialization of the GUI\n",
    "Data_dict={}\n",
    "Classes_color_dict={'Classes Labels': {}, 'Classes Colors': {}}\n",
    "Features_color_groups={'Groups & parameters': {}, 'Colors of groups': {}}\n",
    "#Initialize the GUI:\n",
    "GUI = iDTGUIfun.InteractiveDecisionTreesGUI(Data_dict, Classes_color_dict, Features_color_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Data Requirements:__\n",
    "\n",
    "1. The dataset should live in the current working directory.\n",
    "\n",
    "2. The dataset should be in csv format and have the following \"properties\":\n",
    "\n",
    " + The first row should be the names of the variables. More specifically, the different columns of the 1st row should contain the names of the input variables (e.g. c_0, H0, I, D etc.).\n",
    " + The first column should contain the indexes of the data points of each variable (e.g. 0,1,2, ... etc)\n",
    " + The last column should be the target variable (the class each data point belong to) and should be named 'Classes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In the GUI that will appear:__\n",
    "\n",
    "1. Type the  name of the file (e.g. filename.csv) in the corresponding 'File' text area widget. For this example type Landslides.csv\n",
    "2. For this example, Header should be fixed at 0, Column should be fixed at -1 and the delimeter should be a comma.\n",
    "3. Check the 'Split in train-test sets' and specify the desired 'Test size' in the text area widget. For this example type 0.25 (0.25 -> 25% of the dataset will be used for testing and the rest 75% for training)\n",
    "4. In the 'Random State seed' widget someone can specify an integer to be used as a seed for the random sampling (when splitting in training and test sets). Using the same seed will ensure that the results will be the same.\n",
    "5. Click the 'Import file' button\n",
    "\n",
    "      __Note 1:__ By clicking the 'Import file' button it may take few seconds or minutes (depending on the computer) to load the dataset.\n",
    "        \n",
    "      __Note 2:__ If someone wants to see the loaded dataset then in a new cell type: GUI.Data_dict['x'] and run the cell. This will give a Pandas dataframe with the training inputs variables and their values. In a new cell type GUI.Data_dict['y'] and run the cell. This will give a Pandas Series with the classes for each data point in the GUI.Data_dict['x']\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe51fbc34f04b4db962be0fa67f0ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Text(value='', description='File', placeholder='Type the file nam…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GUI.ImportDatasetGUI()\n",
    "GUI.Import_file_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the GUI developed to define the classes of the dataset and pick colors for each class. In the GUI that will appear:\n",
    "\n",
    "+ Type the name of the class in the correspodning text area widget that will appear.\n",
    "     - The names of the classes should be the same as the ones included in the csv file we imported. For this example there are two classes in the dataset: 'Failure' and 'Stable'. 'Failure' class should be typed first.\n",
    "+ Click the 'Add Class Label' button\n",
    "+ Click on the colored box to open the color picker box. Pick a color and click ok. Or, type the name of the colour in the corresponding text area of the widget. \n",
    "+ Click the 'Assign color to the Class' button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15911baed8444ae4aca93be5471bee14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Text(value='', description='Class Name', placeholder='Type the cl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initialize the GUI:\n",
    "GUI.DefineClassesGUI()\n",
    "\n",
    "#Define Classes Box\n",
    "GUI.classes_labels_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Derive the Statistically Optimal Tree:\n",
    "\n",
    "## 3.1 Estimate the optimal values of certain parameters\n",
    "\n",
    "We derive a Statistically optimal tree (SOT) by optimizing the values of certain parameters that control the tree structure using the Exhaustive Grid Search from sklearn library (for more details: https://scikit-learn.org/0.15/modules/grid_search.html ).\n",
    "\n",
    "1. We set up the parameter space grid with the following parameters (and their ranges):\n",
    "    + Criterion: [gini, entropy]\n",
    "    + Max_leaf_nodes: [15:30, step=1]\n",
    "    + Min_impurity_decrease: [10^-5, 10^-6, 10^-7]\n",
    "2. We set a 10-fold Cross validation search\n",
    "\n",
    "In Exhaustive Grid Search all the possible combinations of parameter values are evaluated, and the best combination is retained. \n",
    "\n",
    "For this example we performed the search described above (the optimization process is not included in this notebook) and we found that optimal values for the above parameters (for the dataset we used) were:\n",
    "- Criterion: 'gini'\n",
    "- Max_leaf_nodes: 29\n",
    "- Min_impurity_decrease: 10^-7\n",
    "\n",
    "*We should note that someone could get different optimal values for the parameters depending on the train and tests sets and/or the parameter ranges used. But for this example we use the values mentioned above.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In the GUI that will appear the user needs to specify the above optimal values for criterion, max_leaf_nodes and min_impurity_decrease using the corresponding widgets. Once the user changes the value of one of 'Decision Tree Structure Controlling Parameters and Plot Formatting' widgets the DT plot will be automatically updated.__ \n",
    "\n",
    "__Note_1:__ It would be good to specify a large maximum depth (e.g. max_depth = 10) to ensure that the DT will have the optimal value of max leaf nodes = 29. If for example the max_depth is fixed at 3 then it is obvious that not all 29 terminal nodes will appear. Moreover, the max_features should be specified to 28 to include all the available variables of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9e8433785d48f6b75519852522b3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='criterion', layout=Layout(width='20%'), options=('gini', 'entropy'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b632ea25b54a6b9ed109ed694fe509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(box_style='info', children=(VBox(children=(HBox(children=(Label(value='Creation of New Composite Variable…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initialize the GUI that contains widgets for interactive construction and analysis of DT\n",
    "GUI.InterConAnalDTGUI()\n",
    "#Output the widgets:\n",
    "GUI.Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Measure the classification accuracy\n",
    "\n",
    "We will calculate the classification accuracy on the training and test sets.\n",
    "\n",
    "In the GUI that will appear the user should:\n",
    "\n",
    "+ Specify the tree state using the dropdown widget:\n",
    "    - If there were no previous interactions with the DT then the user should select the 'No expert tree interactions'. This is the case in this example.\n",
    "    - If the last interaction with the DT was manual changing of variable and/or threshold to split then the user should select the option 'Tree was last modified'\n",
    "    - If the last interaction with the DT was manual pruning then the user needs to select the option 'Tree was last pruned'\n",
    "+ Then click on the 'Calculate accuracy' button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f8c377602240d3981064c8c88f1a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(box_style='info', children=(VBox(box_style='info', children=(HBox(box_style='info', children=(Dropdown(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Output the evaluation widgets\n",
    "GUI.Eval_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Derive the interactive DT (iDT)\n",
    "\n",
    "## 4.1 Pre-group variables based on physical meaning and colour code the groups\n",
    "\n",
    "In this example our first interaction with the DT is to group the variables of the dataset based on the physical characteristics they describe and color code the groups, as shown in the Table below:\n",
    "\n",
    "![image.png](Features_Groups_and_colors.png)\n",
    "\n",
    "To do that we used the tool we developed. In the GUI that will appear the user should:\n",
    "\n",
    "- Type the Group name in the text area widget (e.g. Geophysical Properties)\n",
    "- Type the names of all the variables belonging to that group.\n",
    "\n",
    "  __Notes:__\n",
    "  \n",
    "  + The variables should be space separated\n",
    "  + The variables names should be the same as they are in the input file dataset. For this example the names that should be typed are shown in the above Table under the column 'Symbol'\n",
    "  + I provide a txt file named 'Parameters_groups_colors' containing the names of the Groups and their variables. Someone could use this txt file to copy paste the variables and groups names here.\n",
    "  \n",
    "- Click the 'Assign Features to Group' button\n",
    "- Click on the colored box to open the color picker box. Pick a color for the group and click ok. Or, type the name of the colour in the corresponding text area of the widget.\n",
    "- Click the 'Assign Color to Group' buttton.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4938dcd9876e437db6749fa8d3f77d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(box_style='info', children=(Text(value='', description='Group', placeholder='Type the group name', style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initialize the GUI for pregrouping variables\n",
    "GUI.PregroupFeaturesGUI()\n",
    "#Output the GUI\n",
    "GUI.Group_feat_col_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the new nodes colouring, the user needs to select the option 'Features Color Groups' from the dropdown menu of the widget named 'nodes coloring', in the GUI that will appear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a7fdeb35794588828b0c04440990bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(box_style='info', children=(VBox(children=(HBox(children=(Label(value='Creation of New Composite Variable…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GUI.Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comments:__\n",
    "\n",
    "This physically based nodes coloring visualization facilitates the expert to spot the physical characteristics that dominate the DT and possible interactions. For example, in this case it is obvious that the first 3 levels of the DT are dominated from Geophysical and Slope Geometry properties. Moreover, someone can notice the repeating combination of variables H0 and c_0 which is an indication that these two variables interact. Most DT algorithms make splits on a single variable. Therefore, non-linear interaction between two variables will emerge on the DT as repeating splits (on different thresholds) on the same two variables.\n",
    "\n",
    "__This brings us to the next interaction we want to achieve: The creation of new composite variables.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Create new Composite variables\n",
    "\n",
    "We will create a new composite variable by relating the two variables that appear to interact. More specifically, we create the Soil_ratio = c_0/H0. Moreover, we know from the scientific literature that rainfall intensity (I) and duration (D) interact in the context of slope stability. This is also confirmed in levels 4 and 5 of our DT. So we create a new composite variable Storm Ratio =-log10(D)/log10(I). \n",
    "\n",
    "To create the new composite variables with the tool we developed, in the GUI that will appear the user should:\n",
    "\n",
    "- Type the variable name (in this case: c_0/H0, and -log(D)/log(I) in the corresponding 'Variable Name' text area widget\n",
    "- Type the group name the new variable should belong.\n",
    "- Type the equation that describes how the variables are related (in this case c_0/H0, -log10(D)/log10(I) )\n",
    "- Click the buttons 'Create Feature' and 'Update Features'.\n",
    "\n",
    "\n",
    "The above will ensure the creation of the new variables and their incroporation to the dataset. But, now the available variables of the dataset are 30 and not 28. __So, the user needs to change the value of max_features widget from 28 to 30.__ This will ensure that the algorithm will be able to select among all the available variables of the datasets to make splits. After these changes the user should be able to see the update DT which will most probably contain the new composite variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b632ea25b54a6b9ed109ed694fe509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(box_style='info', children=(VBox(children=(HBox(children=(Label(value='Creation of New Composite Variable…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#For the update Features button to work we need to initialize the GUI SelectFeaturesGUI.\n",
    "GUI.SelectFeaturesGUI() \n",
    "\n",
    "\n",
    "GUI.Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Evaluate its classification perfomance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the case of the SOT we will now calculate the classification accuracy of the iDT on the training and test sets.\n",
    "\n",
    "In the GUI that will appear the user should:\n",
    "\n",
    "+ Specify the tree state using the dropdown widget:\n",
    "    - Select the option 'No expert tree interactions'. This might be a bit confusing. The interaction here refers to interaction with the DT. However, in this example we interacted by making changes to the data not the DT itself. These interactions with the data obviously had an effect on the DT.\n",
    "+ Then click on the 'Calculate accuracy' button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f52d31e2a074d1bb178817ae68173c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(box_style='info', children=(VBox(box_style='info', children=(HBox(box_style='info', children=(Dropdown(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GUI.Eval_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comments:__\n",
    "\n",
    "The accuracy on the training and test sets has improved. If we incorporate the new composite variables and keep the same complexity in the DT we can achieve more accurate results. \n",
    "\n",
    "However, there is a better way to go here. Since with the new variables we achieved higher accuracy we can now reduce the number of leaf nodes. This will obviously reduce the classification accuracy but it will improve interpretability because we will end up with a smaller DT. If someone uses lower values than 29 (which was the optimal value for the SOT) for max_leaf_nodes, the user should see that the classification accuracy remains high for the iDT (even higher than the SOT) even with much less leaves nodes. \n",
    "\n",
    "__To conclude the creation of the two composite variables enabled the identification of a smaller DT, which contributes to increased interpretability.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. References\n",
    "\n",
    "Almeida, S., Holcombe, E., Pianosi, F., & Wagener, T. (2017). Dealing with deep uncertainties in landslide modelling for disaster risk reduction under climate change. Natural Hazards and Earth System Sciences, 17(2), 225-241."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
