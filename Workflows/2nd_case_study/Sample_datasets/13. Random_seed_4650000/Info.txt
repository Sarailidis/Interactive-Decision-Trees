Stat Opt Tree:
DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=19,
                       min_impurity_decrease=1e-05, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=None, splitter='best')

The optimal tree here is with 19 nodes. But in order to calculate the classification accuracies
I had to increase to 20 nodes cause I have 20 nodes in the modified tree.

Accuracy - Train = 0.816
Accuracy - Test = 0.68

iDT:
Accuracy - Train = 0.809
Accuracy - Test = 0.692

Derivation of iDT:
Changes to nodes thresholds:
Node 1  (of SOT DT): From Pm<=294.09 to Pm<=250 (Max_leaf_nodes_left = 4, Max_leaf_nodes_right = 12)
Node 10 (of last modified tree): From Pm<=669.77 to Pm<=500 (Max_leaf_nodes_left = 2, Max_leaf_nodes_right = 3)
Node 3 (of last modified tree): From Pm<=97.711 to Pm<=125 (Max_leaf_nodes_left = 2, Max_leaf_nodes_right = 2)
Node 6 (of last modified tree): From Pm<=1010.9 to Pm<=1000 (Max_leaf_nodes_left = 2, Max_leaf_nodes_right = 2)


Manually change nodes thresholds:
Node 32  (of the last modified tree)
Node 38  (of the last pruned tree)

